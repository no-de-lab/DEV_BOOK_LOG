page table은 아무래도 성능적으로 오버헤드가 크다. 
느리기도 하다. 

## 어떻게 하면 속도를 빠르게 할 수 있을까?
hardware의 힘을 빌린다 : 
Translation-lookaside buffer = TLB
- 우선 tlb를 확인하고 만약 translation 정보가 있으면 바로 진행한다.
- 이는 하드웨어 캐시와 같다. 

## TLB algorithm
- virtual page number를 추출해서 그것이 tlb에 있는지 확인한다.
  - 있으면 tlb hit,
  - 없으면 tlb miss
    - 하드웨어가 페이지 테이블에 접근하여 tlb를 업데이트하게된다. (추가적 메모리가 필요하다.)
- 최대한 tlb miss가 없는 것이 좋다. 페이징 비용이 높다. 

## Example: Accessing An Array
만일 한 페이지에 16바이트인 공간에 4바이트 10개의 프로세스를 넣는다고 가정했을 때, 
한 페이지에 많아야 4개씩 담을 수 있다. 여기서 TLB를 적용하면: 새 페이지로 프로세스가 넘어갔을 때만 tlb miss가 나고 나머지는 tlb hit가 나서, 70% 정도의 성능 개선이 일어난다. 
만약 페이지가 32바이트면 더욱 더 미스가 일어나지 않게 된다. 
- 만약 loop이 돌아 다시 한번 이 배열을 돌게되면 temporal 지역성 때문에 전부 hit 하게 될 것이다. 이 지역성은 hit rate를 높일 것이다. 

## 무엇이 TLB miss를 핸들링하나요? 
- 하드웨어 아니면 OS인데, 
  - 옛날에는 하드웨어의 명령어가 복잡해서 (OS를 못 믿었다.) TLB miss를 하드웨어가 전체적으로 맡았다. 
    - 그래서, 하드웨어가 어디에 페이지 테이블이 있는지 다 알아야 했다.
    - 미스가 나면, 하드웨어가 페이지 테이블로 가서, 정확한 엔트리를 찾아 업데이트했다. 이는 인텔 x86버전에서 그러하다. 
  - 최근에는 명령어가 단순하다. 이 경우 OS가 맡는다. 
    - 트랩 핸들러가 TLB를 업데이트 하기 위한 명령어를 발생시킨다. 그리고 트랩에서 돌아온다. 근데 돌아왔을 때, 다른 return-from-trap과는 다른점이 있다. 
    - 트랩에서 돌아오면 기존에는 해당 트랩 다음부터 진행하는 데 반해, 이 경우에는 다시 tlb를 호출한다.

## TLB 안에는 무엇이 들어있나요? 
- 32, 64, 128개 정도의 엔트리가 있다. 하드웨어는 병렬로 모든 traslation을 검색한다. 
- VPN, PFN,...
- 각 엔트리에 vpn, pfn이 존재한다. valid bit, protection bit,.. 등도 있다. 
- fully associative cache. 즉 여러 캐시 엔트리를 하나 세트에 포함한다.

## TLB issue: Context switch
- 컨텍스트 스위칭이 일어날 때의 문제는 TLB 내에서 어떤 페이지 테이블을 참조하고있는지 모르는 채 잘못된 translation 정보를 참조할 수 있다는 것이다. 
- 따라서 이를 관리할 방법이 필요한데, 그 중 하나는 아예 초기화 해버리는 것이다. 
  - 그러나 이는 아무래도 tlb miss를 점점 늘려서 느린 프로그램을 만들어버릴 것이다.
- 그래서, 주소 공간 identifier(ASID)를 tlb 내에서 만들어서 어떤 프로세스의 정보인지를 기재한다. 
  - 이는 8비트 정도의 공간이다. 
  - 이를 통하여 여러 프로세스의 virtual number가 같은 물리적 메모리 번호를 가리킨다 할지라도 오히려 물리적 메모리를 아끼는 결과를 낳을 수 있다.

## 이슈: Replacement Policy
- 만약 캐시를 교체해야하는 상황이 온다면? 오래된 것과 교체해야할 것이다. 목표는 hit rate를 증가하는 것이어야만 한다.

- 여러 정책이 있으나, 대표적인 적은 LRU, random이다

